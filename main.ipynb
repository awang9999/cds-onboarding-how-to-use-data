{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd0556a",
   "metadata": {},
   "source": [
    "# CDS Onboarding: How To Use Data\n",
    "\n",
    "This Jupyter notebook contains the code associated with \"How To Use Data in Data Science\", a talk given by Alexander Wang to CDS recruits in Fall 2021. The goal of this notebook is to demonstrate:\n",
    "* How to read raw data from .csv files into Pandas DataFrames,\n",
    "* How to prepare data for use in machine learning models from a library (Scikit-Learn, PyTorch),\n",
    "* And how to run machine learning models using the prepared data.\n",
    "\n",
    "Now let's get started! First, we need to import the libraries used throughout this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print(\"Successfully completed imports!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4ac56",
   "metadata": {},
   "source": [
    "Next, we will read the Iris flowers dataset from the file. The dataset is located at the local path `\"datasets/iris.csv\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('datasets/iris.csv')\n",
    "\n",
    "# This prints the head() and tail() of the Pandas DataFrame\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be2ad9",
   "metadata": {},
   "source": [
    "Next, we standardize the columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ad1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 NumPy ndarrays from the feature vector and classification labels of the raw_data respectively. \n",
    "raw_X = raw_data[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]].to_numpy()\n",
    "y = raw_data[\"class\"].to_numpy()\n",
    "\n",
    "scaler = StandardScaler().fit(raw_X)\n",
    "standardized_X = scaler.transform(raw_X)\n",
    "\n",
    "# Print the head of the array\n",
    "standardized_X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd835387",
   "metadata": {},
   "source": [
    "Next, we split the dataset into training and testing sets. Additionally, we parallel shuffle the dataset in order to sufficiently mix up the samples prior to training a model prior to the train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(standardized_X) == len(y))\n",
    "\n",
    "permutation = np.random.permutation(len(y))\n",
    "standardized_X = standardized_X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(standardized_X, y, test_size = 0.4)\n",
    "\n",
    "print(f\"Length of X_train: {len(X_train)}; Length of X_test: {len(X_test)};Length of y_train: {len(y_train)}; Length of y_test: {len(y_test)}\")\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbede75f",
   "metadata": {},
   "source": [
    "Finally, we use X_train and y_train to train a machine learning model. We will be using scikit-learn's implementation of the Logistic Regression classifier model. Although the usage of scikit-learn is beyond the scope of this session, this process will be very similar for any other models in the library. Analogous processes also exist for other machine learning libraries, but they will obviously differ slightly in that they don't make use of the scikit-learn functions.\n",
    "\n",
    "We will also evaluate the accuracy of the trained model using the X_test and y_test sets. It should produce an accuracy greater than 0.90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of LogisticRegression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "#print(y_pred)\n",
    "#print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
